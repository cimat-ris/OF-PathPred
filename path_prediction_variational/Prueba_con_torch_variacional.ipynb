{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Prueba_con_torch_variacional.ipynb","provenance":[{"file_id":"19NEdCOFkz192E98RYrt3dC_jtWhqp8BR","timestamp":1612389852697}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"em2aVoafL-ML"},"source":["# Para ejecutar en Google Colab en Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJhAwN4z7jJ9","executionInfo":{"status":"ok","timestamp":1626216648545,"user_tz":300,"elapsed":1183,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}},"outputId":"4bddcff6-8536-41d9-d105-2dbc23fecaf6"},"source":["# Montamos el Drive al Notebook\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnCMtpvc7n1s","executionInfo":{"status":"ok","timestamp":1626216650801,"user_tz":300,"elapsed":394,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}},"outputId":"79a7a3a2-6c71-4c17-c89f-85e98bc28297"},"source":["# Verificamos el directorio en el que nos encontramos\n","!pwd\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OoAkWfZL7oCL","executionInfo":{"status":"ok","timestamp":1626216652277,"user_tz":300,"elapsed":431,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}},"outputId":"a6b806df-70b5-41ed-b70f-7393858de298"},"source":["# Cambiamos de directorio al Drive\n","import os\n","os.chdir(\"drive/My Drive/PruebasCOLAB2/path_prediction_variational\")\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["background.npy\t\t   linear_variational.py\t       savefigure.py\n","base_variational_layer.py  Prueba_con_torch_variacional.ipynb  test_loo.py\n","lib\t\t\t   rnn_variational.py\t\t       training_loo.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hYovpqgdMNjU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3GM2YmtlMTXp"},"source":["# Inicio de CÃ³digo"]},{"cell_type":"code","metadata":{"id":"2hOKb3HV6YKm","executionInfo":{"status":"ok","timestamp":1626216661406,"user_tz":300,"elapsed":5361,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["# Imports\n","import sys,os\n","''' TF_CPP_MIN_LOG_LEVEL\n","0 = all messages are logged (default behavior)\n","1 = INFO messages are not printed\n","2 = INFO and WARNING messages are not printeds\n","3 = INFO, WARNING, and ERROR messages are not printed\n","'''\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","sys.path.append('lib/')\n","import math,numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Important imports\n","import matplotlib.pyplot as plt\n","\n","from datasets_utils import setup_loo_experiment, get_testing_batch"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uB-rhO4sCDM","executionInfo":{"status":"ok","timestamp":1626216667631,"user_tz":300,"elapsed":3979,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}},"outputId":"342baf1b-b6fd-43b7-db83-62e16398b617"},"source":["import torch\n","torch.manual_seed(1)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f84d73944d0>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"yVOfPyeJGsOj","executionInfo":{"status":"ok","timestamp":1626216670573,"user_tz":300,"elapsed":161,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["# Parameters\n","# The only datasets that can use add_social are those of ETH/UCY\n","# The only datasets that can use add_kp are PETS2009-S2L1, TOWN-CENTRE\n","class Experiment_Parameters:\n","    def __init__(self,add_social=False,add_kp=False,obstacles=False):\n","        # Maximum number of persons in a frame\n","        self.person_max =70\n","        # Observation length (trajlet size)\n","        self.obs_len    = 8\n","        # Prediction length\n","        self.pred_len   = 12\n","        # Flag to consider social interactions\n","        self.add_social = add_social\n","        # Number of key points\n","        self.kp_num     = 18\n","        # Key point flag\n","        self.add_kp     = add_kp\n","        # Obstacles flag\n","        self.obstacles    = obstacles\n","        self.intersection = False\n","        self.delim        = ','\n","        self.output_representation = 'dxdy' #"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"9KnuOybYI8pr","executionInfo":{"status":"ok","timestamp":1626216672102,"user_tz":300,"elapsed":136,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["class Model_Parameters(object):\n","    \"\"\"Model parameters.\n","    \"\"\"\n","    def __init__(self, add_attention=True, add_kp=False, add_social=False, output_representation='dxdy'):\n","        # -----------------\n","        # Observation/prediction lengths\n","        self.obs_len        = 8\n","        self.pred_len       = 12\n","        self.seq_len        = self.obs_len + self.pred_len\n","        self.add_kp         = add_kp\n","        self.add_social     = add_social\n","        self.add_attention  = add_attention\n","        self.stack_rnn_size = 2\n","        self.output_representation = output_representation\n","        self.output_var_dirs= 0\n","        # Key points\n","        self.kp_size        = 18\n","        # Optical flow\n","        self.flow_size      = 64\n","        # For training\n","        self.num_epochs     = 35\n","        self.batch_size     = 256  # batch size 512\n","        self.use_validation = True\n","        # Network architecture\n","        self.P              =   2 # Dimensions of the position vectors\n","        self.enc_hidden_size= 256                  # Default value in NextP\n","        self.dec_hidden_size= self.enc_hidden_size # Default value in NextP\n","        self.emb_size       = 128  # Default value in NextP\n","        self.dropout_rate   = 0.3 # Default value in NextP\n","\n","        #self.activation_func= tf.nn.tanh\n","        self.multi_decoder  = False\n","        self.modelname      = 'gphuctl'\n","        self.optimizer      = 'adam'\n","        self.initial_lr     = 0.01\n","        # MC dropout\n","        self.is_mc_dropout         = False\n","        self.mc_samples            = 20\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"oYyijVou6YKq","executionInfo":{"status":"ok","timestamp":1626216675247,"user_tz":300,"elapsed":205,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["# Load the default parameters\n","experiment_parameters = Experiment_Parameters(add_social=False,add_kp=False,obstacles=False)\n","\n","dataset_dir   = \"../datasets/\"\n","dataset_names = ['eth-hotel','eth-univ','ucy-zara01','ucy-zara02','ucy-univ']"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bySxfWOc6YKs","executionInfo":{"status":"ok","timestamp":1626216963560,"user_tz":300,"elapsed":54443,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}},"outputId":"5529c0c1-2034-4030-9dbd-d6bf5fa79019"},"source":["# Load the dataset and perform the split\n","training_data, validation_data, test_data, test_homography = setup_loo_experiment('ETH_UCY',dataset_dir,dataset_names,2,experiment_parameters,use_pickled_data=False)\n","\n","print('obs_traj: ',training_data['obs_traj'].shape)\n","print('obs_traj_rel: ',training_data['obs_traj_rel'].shape)\n","print('obs_traj_theta: ',training_data['obs_traj_theta'].shape)\n","print('pred_traj: ',training_data['pred_traj'].shape)\n","print('pred_traj_rel: ',training_data['pred_traj_rel'].shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[INF] Testing/validation dataset: ['ucy-zara01']\n","[INF] Training datasets: ['eth-hotel', 'eth-univ', 'ucy-zara02', 'ucy-univ']\n","[INF] Extracting data from the datasets\n","[INF] Sequence length (observation+prediction): 20\n","[INF] Reading ../datasets/ucy-zara01/mundo/mun_pos.csv\n","[INF] Total number of frames:  872\n","[INF] Total number of sample sequences:  2356\n","[INF] Sequence length (observation+prediction): 20\n","[INF] Reading ../datasets/eth-hotel/mundo/mun_pos.csv\n","[INF] Total number of frames:  1168\n","[INF] Reading ../datasets/eth-univ/mundo/mun_pos.csv\n","[INF] Total number of frames:  876\n","[INF] Reading ../datasets/ucy-zara02/mundo/mun_pos.csv\n","[INF] Total number of frames:  1052\n","[INF] Reading ../datasets/ucy-univ/mundo/mun_pos.csv\n","[INF] Total number of frames:  541\n","[INF] Total number of sample sequences:  17201\n","[INF] Training data: 15481\n","[INF] Test data: 2356\n","[INF] Validation data: 1720\n","obs_traj:  (15481, 8, 2)\n","obs_traj_rel:  (15481, 8, 2)\n","obs_traj_theta:  (15481, 8, 1)\n","pred_traj:  (15481, 12, 2)\n","pred_traj_rel:  (15481, 12, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"00GpCrbg6YKt","executionInfo":{"status":"ok","timestamp":1626217018285,"user_tz":300,"elapsed":134,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["#############################################################\n","# Model parameters\n","model_parameters = Model_Parameters(add_attention=True,add_kp=experiment_parameters.add_kp,add_social=experiment_parameters.add_social,output_representation=experiment_parameters.output_representation)\n","\n","model_parameters.num_epochs     = 5\n","model_parameters.output_var_dirs= 0\n","model_parameters.is_mc_dropout  = False # poner a False\n","model_parameters.initial_lr     = 0.03\n","model_parameters.dropout_rate   = 0\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZF0jBL9pWppF","executionInfo":{"status":"ok","timestamp":1626217024480,"user_tz":300,"elapsed":493,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","\n","# Creamos la clase para el dataset\n","class traj_dataset(Dataset):\n","\n","    def __init__(self, Xrel_Train, Yrel_Train, X_Train, Y_Train, transform=None):\n","        self.Xrel_Train = Xrel_Train\n","        self.Yrel_Train = Yrel_Train\n","        self.X_Train = X_Train\n","        self.Y_Train = Y_Train\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.X_Train)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        xrel = self.Xrel_Train[idx]\n","        yrel = self.Yrel_Train[idx]\n","        x = self.X_Train[idx]\n","        y = self.Y_Train[idx]\n","\n","        if self.transform:\n","            x = self.transform(x)\n","            y = self.transform(y)\n","            xrel = self.transform(xrel)\n","            yrel = self.transform(yrel)\n","\n","        return xrel, yrel, x, y"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnCdyKzuW_gI","executionInfo":{"status":"ok","timestamp":1626217038070,"user_tz":300,"elapsed":143,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["# Creamos el dataset para torch\n","train_data = traj_dataset(training_data['obs_traj_rel'], training_data['pred_traj_rel'],training_data['obs_traj'], training_data['pred_traj'])\n","val_data = traj_dataset(validation_data['obs_traj_rel'], validation_data['pred_traj_rel'],validation_data['obs_traj'], validation_data['pred_traj'])\n","test_data = traj_dataset(test_data['obs_traj_rel'], test_data['pred_traj_rel'], test_data['obs_traj'], test_data['pred_traj'])"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"5j23o7zkGh1A","executionInfo":{"status":"ok","timestamp":1626217045689,"user_tz":300,"elapsed":135,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["# Form batches\n","batched_train_data = torch.utils.data.DataLoader( train_data, batch_size = model_parameters.batch_size, shuffle=True)\n","batched_val_data =  torch.utils.data.DataLoader( val_data, batch_size = model_parameters.batch_size, shuffle=True)\n","batched_test_data =  torch.utils.data.DataLoader( test_data, batch_size = model_parameters.batch_size, shuffle=True)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRwsEyE2emM4","executionInfo":{"status":"ok","timestamp":1626217050435,"user_tz":300,"elapsed":1285,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from rnn_variational import *\n","from linear_variational import *\n","\n","prior_mu = 0.0\n","prior_sigma = 1.0\n","posterior_mu_init = 0.0\n","posterior_rho_init = -4 #-3.0 # 0.006715348489117967 # 0.01814992791780978 # 0.04858735157374196\n","\n","len_trainset = 15481\n","len_valset = 1720\n","\n","\n","class LSTM_variational(nn.Module):\n","    def __init__(self, in_size,  embedding_dim, hidden_dim, output_size):\n","        super(LSTM_variational, self).__init__()\n","\n","        # layer linear\n","        self.embedding = LinearReparameterization(\n","            in_features = in_size,\n","            out_features = embedding_dim, # 128\n","            prior_mean = prior_mu,\n","            prior_variance = prior_sigma,\n","            posterior_mu_init = posterior_mu_init,\n","            posterior_rho_init = posterior_rho_init,\n","        )\n","\n","        # layer lstm\n","        self.lstm1 = LSTMReparameterization(\n","            in_features = embedding_dim,\n","            out_features = hidden_dim, # 256\n","            prior_mean = prior_mu,\n","            prior_variance = prior_sigma,\n","            posterior_mu_init = posterior_mu_init,\n","            posterior_rho_init = posterior_rho_init,\n","        )\n","\n","        # layer lstm\n","        self.lstm2 = LSTMReparameterization(\n","            in_features = embedding_dim,\n","            out_features = hidden_dim, # 256\n","            prior_mean = prior_mu,\n","            prior_variance = prior_sigma,\n","            posterior_mu_init = posterior_mu_init,\n","            posterior_rho_init = posterior_rho_init,\n","        )\n","\n","        # layer linear\n","        self.decoder = LinearReparameterization(\n","            in_features = hidden_dim,\n","            out_features = output_size, # 12\n","            prior_mean = prior_mu,\n","            prior_variance = prior_sigma,\n","            posterior_mu_init = posterior_mu_init,\n","            posterior_rho_init = posterior_rho_init,\n","        )\n","\n","        #self.loss_fun = nn.CrossEntropyLoss()\n","        self.loss_fun = nn.MSELoss()\n","\n","    def forward(self, X, y, training=False, num_mc=1):\n","      \n","        output_ = []\n","        kl_ = []\n","        for mc_run in range(num_mc):\n","            # Copy data\n","            x = X\n","            # Last position traj\n","            x_last = X[:,-1,:].view(len(x), 1, -1) \n","\n","            kl_sum = 0\n","            # Layers\n","            emb, kl = self.embedding(X) # encoder for batch\n","            kl_sum += kl\n","            lstm_out, (hn1, cn1), kl = self.lstm1(emb)\n","            kl_sum += kl\n","\n","            # Iterate for each time step\n","            pred = [] \n","            for i, target in enumerate(y.permute(1,0,2)):\n","                emb_last, kl = self.embedding(x_last) # encoder for last position\n","                kl_sum += kl\n","                lstm_out, (hn2, cn2), kl = self.lstm2(emb_last, (hn1[:,-1,:],cn1[:,-1,:]))\n","                kl_sum += kl\n","\n","                # Decoder and Prediction\n","                dec, kl = self.decoder(hn2)\n","                kl_sum += kl\n","                t_pred = dec + x_last\n","                pred.append(t_pred)\n","\n","                # Update the last position\n","                if training:\n","                    x_last = target.view(len(target), 1, -1)\n","                    len_evaldataset = len_trainset\n","                else:\n","                    x_last = t_pred\n","                    len_evaldataset = len_valset\n","                hn1 = hn2\n","                cn1 = cn2\n","\n","            # Concatenate the trajectories preds\n","            pred = torch.cat(pred, dim=1)\n","\n","            # save to list\n","            output_.append(pred)\n","            kl_.append(kl_sum)\n","\n","        pred = torch.mean(torch.stack(output_), dim=0)\n","        kl = torch.mean(torch.stack(kl_), dim=0)\n","\n","        # Calculate of loss\n","        nll_loss = self.loss_fun(pred, y)\n","\n","        #ELBO loss\n","        #loss = nll_loss + (kl / len_evaldataset)\n","        loss = nll_loss + (kl / y.shape[0])\n","\n","        # Concatenate the predictions and return\n","        return pred, loss\n","\n","    def predict(self, X, dim_pred= 1):\n","\n","      # Copy data\n","      x = X\n","      # Last position traj\n","      x_last = X[:,-1,:].view(len(x), 1, -1) \n","\n","      kl_sum = 0\n","      # Layers\n","      emb, kl = self.embedding(X) # encoder for batch\n","      kl_sum += kl\n","      lstm_out, (hn1, cn1), kl = self.lstm1(emb)\n","      kl_sum += kl\n","\n","      # Iterate for each time step\n","      pred = [] \n","      for i in range(dim_pred):\n","          emb_last, kl = self.embedding(x_last) # encoder for last position\n","          kl_sum += kl\n","          lstm_out, (hn2, cn2), kl = self.lstm2(emb_last, (hn1[:,-1,:],cn1[:,-1,:]))\n","          kl_sum += kl\n","\n","          # Decoder and Prediction\n","          dec, kl = self.decoder(hn2)\n","          kl_sum += kl\n","          t_pred = dec + x_last\n","          pred.append(t_pred)\n","\n","          # Update the last position\n","          x_last = t_pred\n","          hn1 = hn2\n","          cn1 = cn2\n","\n","      # Concatenate the predictions and return\n","      return torch.cat(pred, dim=1).detach().numpy(), kl_sum\n","      "],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nl081RMM42N"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-2DsuYRjGrvw","executionInfo":{"status":"ok","timestamp":1626217128372,"user_tz":300,"elapsed":126,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["# Model\n","model = LSTM_variational(2,128,256,2)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2g_bvInYjAJZ","executionInfo":{"status":"ok","timestamp":1626218033804,"user_tz":300,"elapsed":903961,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}},"outputId":"d83ede94-42e2-4494-fd21-3f30485d61ef"},"source":["import torch.optim as optim\n","\n","# Training the Model\n","optimizer = optim.SGD(model.parameters(), lr=model_parameters.initial_lr)\n","\n","#optimizer = optim.SGD(model.parameters(), lr=0.015)\n","#optimizer = optim.SGD(model.parameters(), lr=0.03)\n","#optimizer = optim.SGD(model.parameters(), lr=0.05)\n","#optimizer = optim.SGD(model.parameters(), lr=0.08) #nan\n","#optimizer = optim.SGD(model.parameters(), lr=0.07) #nan \n","#optimizer = optim.SGD(model.parameters(), lr=0.06) #nan \n","\n","epochs = model_parameters.num_epochs\n","num_mc = 5\n","\n","for epoch in range(epochs):\n","    # Training\n","    print(\"----- \")\n","    print(\"epoch: \", epoch)\n","    error = 0\n","    total = 0\n","    for batch_idx, (data, target, _a , _b) in enumerate(batched_train_data):\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance\n","        model.zero_grad()\n","\n","        # Step 2. Run our forward pass and compute the loss\n","        \n","        pred, loss = model(data, target, training=True, num_mc=num_mc)\n","\n","        #pred, loss = model(data, target)\n","        error += loss\n","        total += len(target)\n","\n","        # Step 3. Compute the gradients, and update the parameters by\n","        loss.backward()\n","        optimizer.step()\n","    print(\"training loss: \", error/total)\n","\n","    # Validation\n","    error = 0\n","    total = 0\n","    for batch_idx, (data_val, target_val, _ , _) in enumerate(batched_val_data):\n","        pred_val, loss_val = model(data_val, target_val)\n","        error += loss_val\n","        total += len(target_val)\n","\n","    print(\"Validation loss: \", error/total)\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["----- \n","epoch:  0\n","training loss:  tensor(431.4666, grad_fn=<DivBackward0>)\n","Validation loss:  tensor(457.0410, grad_fn=<DivBackward0>)\n","----- \n","epoch:  1\n","training loss:  tensor(422.1804, grad_fn=<DivBackward0>)\n","Validation loss:  tensor(447.1103, grad_fn=<DivBackward0>)\n","----- \n","epoch:  2\n","training loss:  tensor(412.9214, grad_fn=<DivBackward0>)\n","Validation loss:  tensor(437.2086, grad_fn=<DivBackward0>)\n","----- \n","epoch:  3\n","training loss:  tensor(403.6894, grad_fn=<DivBackward0>)\n","Validation loss:  tensor(427.3356, grad_fn=<DivBackward0>)\n","----- \n","epoch:  4\n","training loss:  tensor(394.4842, grad_fn=<DivBackward0>)\n","Validation loss:  tensor(417.4915, grad_fn=<DivBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"99A6ayLglGmV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LtBmwWGBHV4b","executionInfo":{"status":"ok","timestamp":1626218044464,"user_tz":300,"elapsed":127,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}}},"source":["def plot_traj(pred_traj, obs_traj_gt, pred_traj_gt, test_homography, background):\n","    print(\"-----\")\n","    homography = np.linalg.inv(test_homography)\n","\n","    # Convert it to absolute (starting from the last observed position)\n","    displacement = np.cumsum(pred_traj, axis=0)\n","    this_pred_out_abs = displacement + np.array([obs_traj_gt[-1].numpy()])\n","\n","    obs   = image_to_world_xy(obs_traj_gt, homography, flip=False)\n","    gt    = image_to_world_xy(pred_traj_gt, homography, flip=False)\n","    gt = np.concatenate([obs[-1,:].reshape((1,2)), gt],axis=0)\n","    tpred   = image_to_world_xy(this_pred_out_abs, homography, flip=False)\n","    tpred = np.concatenate([obs[-1,:].reshape((1,2)), tpred],axis=0)\n","\n","    plt.figure(figsize=(12,12))\n","    plt.imshow(background)\n","    plt.plot(obs[:,0],obs[:,1],\"-b\", linewidth=2, label=\"Observations\")\n","    plt.plot(gt[:,0], gt[:,1],\"-r\", linewidth=2, label=\"Ground truth\")\n","    plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2, label=\"Prediction\")\n","    plt.legend()\n","    plt.title('Trajectory samples')\n","    plt.show()\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"30joaw2kMWDY","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1HCeVlXQLYZVwBDinWWjWtxv6QEqFgd2u"},"executionInfo":{"status":"ok","timestamp":1626218110872,"user_tz":300,"elapsed":61967,"user":{"displayName":"Mario Xavier Canche Uc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64","userId":"15987765480396593536"}},"outputId":"4c9ae6b1-9a48-4b16-a59b-612ab8fd3024"},"source":["from obstacles import image_to_world_xy\n","\n","num_samples = 30\n","num_monte_carlo = 20\n","i = 1 # sample of batch\n","bck = np.load('background.npy')\n","\n","# Testing\n","cont = 0\n","for batch_idx, (datarel_test, targetrel_test, data_test, target_test) in enumerate(batched_test_data):\n","    print(\"-----\")\n","    print(cont)\n","    homography = np.linalg.inv(test_homography)\n","    \n","    obs_traj_gt = data_test[i,:,:]\n","    pred_traj_gt = target_test[i,:,:]\n","    obs   = image_to_world_xy(obs_traj_gt, homography, flip=False)\n","    gt    = image_to_world_xy(pred_traj_gt, homography, flip=False)\n","    gt = np.concatenate([obs[-1,:].reshape((1,2)), gt], axis=0)\n","\n","    plt.figure(figsize=(12,12))\n","    plt.imshow(bck)\n","    plt.plot(obs[:,0],obs[:,1],\"-b\", linewidth=2, label=\"Observations\")\n","    plt.plot(gt[:,0], gt[:,1],\"-r\", linewidth=2, label=\"Ground truth\")\n","\n","    # prediction\n","    for mc_run in range(num_monte_carlo):\n","        pred, kl = model.predict(datarel_test, dim_pred=12)\n","        # ploting \n","        #plot_traj(pred[i,:,:], data_test[i,:,:], target_test[i,:,:], test_homography, bck)\n","\n","        pred_traj = pred[i,:,:]\n","\n","        # Convert it to absolute (starting from the last observed position)\n","        displacement = np.cumsum(pred_traj, axis=0)\n","        this_pred_out_abs = displacement + np.array([obs_traj_gt[-1].numpy()])\n","\n","        tpred   = image_to_world_xy(this_pred_out_abs, homography, flip=False)\n","        tpred = np.concatenate([obs[-1,:].reshape((1,2)), tpred], axis=0)\n","\n","        if mc_run == 0:\n","            plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2, label=\"Prediction\")\n","        else:\n","            plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2)\n","\n","    plt.legend()\n","    plt.title('Trajectory samples')\n","    plt.savefig(\"traj_variational_1_4\"+str(cont)+\".pdf\")\n","    plt.show()\n","\n","    cont += 1\n","        \n","    if cont == num_samples:\n","        break"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"HpU2HvaQKObj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRpI157sKOeG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n38rE4UKKOhC"},"source":[""],"execution_count":null,"outputs":[]}]}