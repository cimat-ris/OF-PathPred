{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em2aVoafL-ML"
   },
   "source": [
    "# Para ejecutar en Google Colab en Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1626216648545,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "qJhAwN4z7jJ9",
    "outputId": "4bddcff6-8536-41d9-d105-2dbc23fecaf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Montamos el Drive al Notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1626216650801,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "pnCMtpvc7n1s",
    "outputId": "79a7a3a2-6c71-4c17-c89f-85e98bc28297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "# Verificamos el directorio en el que nos encontramos\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1626216652277,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "OoAkWfZL7oCL",
    "outputId": "a6b806df-70b5-41ed-b70f-7393858de298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background.npy\t\t   linear_variational.py\t       savefigure.py\n",
      "base_variational_layer.py  Prueba_con_torch_variacional.ipynb  test_loo.py\n",
      "lib\t\t\t   rnn_variational.py\t\t       training_loo.py\n"
     ]
    }
   ],
   "source": [
    "# Cambiamos de directorio al Drive\n",
    "import os\n",
    "os.chdir(\"drive/My Drive/PruebasCOLAB2/path_prediction_variational\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYovpqgdMNjU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GM2YmtlMTXp"
   },
   "source": [
    "# Inicio de CÃ³digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 5361,
     "status": "ok",
     "timestamp": 1626216661406,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "2hOKb3HV6YKm"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys,os\n",
    "''' TF_CPP_MIN_LOG_LEVEL\n",
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printeds\n",
    "3 = INFO, WARNING, and ERROR messages are not printed\n",
    "'''\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "sys.path.append('lib/')\n",
    "sys.path.append('lib/')\n",
    "import math,numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Important imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets_utils import setup_loo_experiment, get_testing_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3979,
     "status": "ok",
     "timestamp": 1626216667631,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "4uB-rhO4sCDM",
    "outputId": "342baf1b-b6fd-43b7-db83-62e16398b617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1)\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1626216670573,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "yVOfPyeJGsOj"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# The only datasets that can use add_social are those of ETH/UCY\n",
    "# The only datasets that can use add_kp are PETS2009-S2L1, TOWN-CENTRE\n",
    "class Experiment_Parameters:\n",
    "    def __init__(self,add_social=False,add_kp=False,obstacles=False):\n",
    "        # Maximum number of persons in a frame\n",
    "        self.person_max =70\n",
    "        # Observation length (trajlet size)\n",
    "        self.obs_len    = 8\n",
    "        # Prediction length\n",
    "        self.pred_len   = 12\n",
    "        # Flag to consider social interactions\n",
    "        self.add_social = add_social\n",
    "        # Number of key points\n",
    "        self.kp_num     = 18\n",
    "        # Key point flag\n",
    "        self.add_kp     = add_kp\n",
    "        # Obstacles flag\n",
    "        self.obstacles    = obstacles\n",
    "        self.intersection = False\n",
    "        self.delim        = ','\n",
    "        self.output_representation = 'dxdy' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1626216672102,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "9KnuOybYI8pr"
   },
   "outputs": [],
   "source": [
    "class Model_Parameters(object):\n",
    "    \"\"\"Model parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, add_attention=True, add_kp=False, add_social=False, output_representation='dxdy'):\n",
    "        # -----------------\n",
    "        # Observation/prediction lengths\n",
    "        self.obs_len        = 8\n",
    "        self.pred_len       = 12\n",
    "        self.seq_len        = self.obs_len + self.pred_len\n",
    "        self.add_kp         = add_kp\n",
    "        self.add_social     = add_social\n",
    "        self.add_attention  = add_attention\n",
    "        self.stack_rnn_size = 2\n",
    "        self.output_representation = output_representation\n",
    "        self.output_var_dirs= 0\n",
    "        # Key points\n",
    "        self.kp_size        = 18\n",
    "        # Optical flow\n",
    "        self.flow_size      = 64\n",
    "        # For training\n",
    "        self.num_epochs     = 35\n",
    "        self.batch_size     = 256  # batch size 512\n",
    "        self.use_validation = True\n",
    "        # Network architecture\n",
    "        self.P              =   2 # Dimensions of the position vectors\n",
    "        self.enc_hidden_size= 256                  # Default value in NextP\n",
    "        self.dec_hidden_size= self.enc_hidden_size # Default value in NextP\n",
    "        self.emb_size       = 128  # Default value in NextP\n",
    "        self.dropout_rate   = 0.3 # Default value in NextP\n",
    "\n",
    "        #self.activation_func= tf.nn.tanh\n",
    "        self.multi_decoder  = False\n",
    "        self.modelname      = 'gphuctl'\n",
    "        self.optimizer      = 'adam'\n",
    "        self.initial_lr     = 0.01\n",
    "        # MC dropout\n",
    "        self.is_mc_dropout         = False\n",
    "        self.mc_samples            = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1626216675247,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "oYyijVou6YKq"
   },
   "outputs": [],
   "source": [
    "# Load the default parameters\n",
    "experiment_parameters = Experiment_Parameters(add_social=False,add_kp=False,obstacles=False)\n",
    "\n",
    "dataset_dir   = \"../datasets/\"\n",
    "dataset_names = ['eth-hotel','eth-univ','ucy-zara01','ucy-zara02','ucy-univ']\n",
    "#dataset_names = ['eth-hotel','eth-univ','ucy-zara01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54443,
     "status": "ok",
     "timestamp": 1626216963560,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "bySxfWOc6YKs",
    "outputId": "5529c0c1-2034-4030-9dbd-d6bf5fa79019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INF] Testing/validation dataset: ['ucy-zara01']\n",
      "[INF] Training datasets: ['eth-hotel', 'eth-univ', 'ucy-zara02', 'ucy-univ']\n",
      "[INF] Extracting data from the datasets\n",
      "[INF] Sequence length (observation+prediction): 20\n",
      "[INF] Reading ../datasets/ucy-zara01/mundo/mun_pos.csv\n",
      "[INF] Total number of frames:  872\n",
      "[INF] Total number of sample sequences:  2356\n",
      "[INF] Sequence length (observation+prediction): 20\n",
      "[INF] Reading ../datasets/eth-hotel/mundo/mun_pos.csv\n",
      "[INF] Total number of frames:  1168\n",
      "[INF] Reading ../datasets/eth-univ/mundo/mun_pos.csv\n",
      "[INF] Total number of frames:  876\n",
      "[INF] Reading ../datasets/ucy-zara02/mundo/mun_pos.csv\n",
      "[INF] Total number of frames:  1052\n",
      "[INF] Reading ../datasets/ucy-univ/mundo/mun_pos.csv\n",
      "[INF] Total number of frames:  541\n",
      "[INF] Total number of sample sequences:  17201\n",
      "[INF] Training data: 15481\n",
      "[INF] Test data: 2356\n",
      "[INF] Validation data: 1720\n",
      "obs_traj:  (15481, 8, 2)\n",
      "obs_traj_rel:  (15481, 8, 2)\n",
      "obs_traj_theta:  (15481, 8, 1)\n",
      "pred_traj:  (15481, 12, 2)\n",
      "pred_traj_rel:  (15481, 12, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and perform the split\n",
    "training_data, validation_data, test_data, test_homography = setup_loo_experiment('ETH_UCY',dataset_dir,dataset_names,2,experiment_parameters,use_pickled_data=False)\n",
    "\n",
    "print('obs_traj: ',training_data['obs_traj'].shape)\n",
    "print('obs_traj_rel: ',training_data['obs_traj_rel'].shape)\n",
    "print('obs_traj_theta: ',training_data['obs_traj_theta'].shape)\n",
    "print('pred_traj: ',training_data['pred_traj'].shape)\n",
    "print('pred_traj_rel: ',training_data['pred_traj_rel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1626217018285,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "00GpCrbg6YKt"
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Model parameters\n",
    "model_parameters = Model_Parameters(add_attention=True,add_kp=experiment_parameters.add_kp,add_social=experiment_parameters.add_social,output_representation=experiment_parameters.output_representation)\n",
    "\n",
    "model_parameters.num_epochs     = 40\n",
    "model_parameters.output_var_dirs= 0\n",
    "model_parameters.is_mc_dropout  = False # poner a False\n",
    "model_parameters.initial_lr     = 0.03\n",
    "model_parameters.dropout_rate   = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1626217024480,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "ZF0jBL9pWppF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Creamos la clase para el dataset\n",
    "class traj_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, Xrel_Train, Yrel_Train, X_Train, Y_Train, transform=None):\n",
    "        self.Xrel_Train = Xrel_Train\n",
    "        self.Yrel_Train = Yrel_Train\n",
    "        self.X_Train = X_Train\n",
    "        self.Y_Train = Y_Train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_Train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        xrel = self.Xrel_Train[idx]\n",
    "        yrel = self.Yrel_Train[idx]\n",
    "        x = self.X_Train[idx]\n",
    "        y = self.Y_Train[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            y = self.transform(y)\n",
    "            xrel = self.transform(xrel)\n",
    "            yrel = self.transform(yrel)\n",
    "\n",
    "        return xrel, yrel, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1626217038070,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "jnCdyKzuW_gI"
   },
   "outputs": [],
   "source": [
    "# Creamos el dataset para torch\n",
    "train_data = traj_dataset(training_data['obs_traj_rel'], training_data['pred_traj_rel'],training_data['obs_traj'], training_data['pred_traj'])\n",
    "val_data = traj_dataset(validation_data['obs_traj_rel'], validation_data['pred_traj_rel'],validation_data['obs_traj'], validation_data['pred_traj'])\n",
    "test_data = traj_dataset(test_data['obs_traj_rel'], test_data['pred_traj_rel'], test_data['obs_traj'], test_data['pred_traj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1626217045689,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "5j23o7zkGh1A"
   },
   "outputs": [],
   "source": [
    "# Form batches\n",
    "batched_train_data = torch.utils.data.DataLoader( train_data, batch_size = model_parameters.batch_size, shuffle=True)\n",
    "batched_val_data =  torch.utils.data.DataLoader( val_data, batch_size = model_parameters.batch_size, shuffle=True)\n",
    "batched_test_data =  torch.utils.data.DataLoader( test_data, batch_size = model_parameters.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1626217050435,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "IRwsEyE2emM4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from rnn_variational import *\n",
    "from linear_variational import *\n",
    "\n",
    "prior_mu = 0.0\n",
    "prior_sigma = 1.0\n",
    "posterior_mu_init = 0.0\n",
    "posterior_rho_init = -3.0 # 0.006715348489117967 # 0.01814992791780978 # 0.04858735157374196\n",
    "\n",
    "len_trainset = 15481\n",
    "len_valset = 1720\n",
    "\n",
    "\n",
    "class LSTM_variational(nn.Module):\n",
    "    def __init__(self, in_size,  embedding_dim, hidden_dim, output_size):\n",
    "        super(LSTM_variational, self).__init__()\n",
    "\n",
    "        # Linear layer\n",
    "        self.embedding = LinearReparameterization(\n",
    "            in_features = in_size,\n",
    "            out_features = embedding_dim, # 128\n",
    "            prior_mean = prior_mu,\n",
    "            prior_variance = prior_sigma,\n",
    "            posterior_mu_init = posterior_mu_init,\n",
    "            posterior_rho_init = posterior_rho_init,\n",
    "        )\n",
    "\n",
    "        # LSTM layer encoder\n",
    "        self.lstm1 = LSTMReparameterization(\n",
    "            in_features = embedding_dim,\n",
    "            out_features = hidden_dim, # 256\n",
    "            prior_mean = prior_mu,\n",
    "            prior_variance = prior_sigma,\n",
    "            posterior_mu_init = posterior_mu_init,\n",
    "            posterior_rho_init = posterior_rho_init,\n",
    "        )\n",
    "\n",
    "        # LSTM layer decoder\n",
    "        self.lstm2 = LSTMReparameterization(\n",
    "            in_features = embedding_dim,\n",
    "            out_features = hidden_dim, # 256\n",
    "            prior_mean = prior_mu,\n",
    "            prior_variance = prior_sigma,\n",
    "            posterior_mu_init = posterior_mu_init,\n",
    "            posterior_rho_init = posterior_rho_init,\n",
    "        )\n",
    "        # Linear layer\n",
    "        self.decoder = LinearReparameterization(\n",
    "            in_features = hidden_dim,\n",
    "            out_features = output_size, # 2\n",
    "            prior_mean = prior_mu,\n",
    "            prior_variance = prior_sigma,\n",
    "            posterior_mu_init = posterior_mu_init,\n",
    "            posterior_rho_init = posterior_rho_init,\n",
    "        )\n",
    "        self.loss_fun = nn.MSELoss()\n",
    "    # \n",
    "    def forward(self, X, y, training=False, num_mc=1):\n",
    "      \n",
    "        output_ = []\n",
    "        kl_     = []\n",
    "        # \n",
    "        nbatches = len(X)\n",
    "        # Last position in the trajectory\n",
    "        x_last = X[:,-1,:].view(nbatches, 1, -1) \n",
    "\n",
    "        # Monte Carlo iterations\n",
    "        for mc_run in range(num_mc):\n",
    "            kl_sum = 0\n",
    "            # Layers\n",
    "            emb, kl = self.embedding(X) # encoder for batch\n",
    "            kl_sum += kl\n",
    "            lstm_out, (hn1, cn1), kl = self.lstm1(emb)\n",
    "            kl_sum += kl\n",
    "\n",
    "            # Iterate for each time step\n",
    "            pred = [] \n",
    "            for i, target in enumerate(y.permute(1,0,2)):\n",
    "                emb_last, kl = self.embedding(x_last) # encoder for last position\n",
    "                kl_sum += kl\n",
    "                lstm_out, (hn2, cn2), kl = self.lstm2(emb_last, (hn1[:,-1,:],cn1[:,-1,:]))\n",
    "                kl_sum += kl\n",
    "\n",
    "                # Decoder and Prediction\n",
    "                dec, kl = self.decoder(hn2)\n",
    "                kl_sum += kl\n",
    "                t_pred = dec + x_last\n",
    "                pred.append(t_pred)\n",
    "\n",
    "                # Update the last position\n",
    "                if training:\n",
    "                    x_last = target.view(len(target), 1, -1)\n",
    "                    len_evaldataset = len_trainset\n",
    "                else:\n",
    "                    x_last = t_pred\n",
    "                    len_evaldataset = len_valset\n",
    "                hn1 = hn2\n",
    "                cn1 = cn2\n",
    "\n",
    "            # Concatenate the trajectories preds\n",
    "            pred = torch.cat(pred, dim=1)\n",
    "\n",
    "            # save to list\n",
    "            output_.append(pred)\n",
    "            kl_.append(kl_sum)\n",
    "\n",
    "        pred    = torch.mean(torch.stack(output_), dim=0)\n",
    "        kl_loss = torch.mean(torch.stack(kl_), dim=0)\n",
    "\n",
    "        # Calculate of nl loss\n",
    "        nll_loss = self.loss_fun(pred, y)\n",
    "        # Concatenate the predictions and return\n",
    "        return pred, nll_loss, kl_loss\n",
    "\n",
    "    def predict(self, X, dim_pred= 1):\n",
    "\n",
    "      # Copy data\n",
    "      x = X\n",
    "      # Last position traj\n",
    "      x_last = X[:,-1,:].view(len(x), 1, -1) \n",
    "\n",
    "      kl_sum = 0\n",
    "      # Layers\n",
    "      emb, kl = self.embedding(X) # encoder for batch\n",
    "      kl_sum += kl\n",
    "      lstm_out, (hn1, cn1), kl = self.lstm1(emb)\n",
    "      kl_sum += kl\n",
    "\n",
    "      # Iterate for each time step\n",
    "      pred = [] \n",
    "      for i in range(dim_pred):\n",
    "          emb_last, kl = self.embedding(x_last) # encoder for last position\n",
    "          kl_sum += kl\n",
    "          lstm_out, (hn2, cn2), kl = self.lstm2(emb_last, (hn1[:,-1,:],cn1[:,-1,:]))\n",
    "          kl_sum += kl\n",
    "\n",
    "          # Decoder and Prediction\n",
    "          dec, kl = self.decoder(hn2)\n",
    "          kl_sum += kl\n",
    "          t_pred = dec + x_last\n",
    "          pred.append(t_pred)\n",
    "\n",
    "          # Update the last position\n",
    "          x_last = t_pred\n",
    "          hn1 = hn2\n",
    "          cn1 = cn2\n",
    "\n",
    "      # Concatenate the predictions and return\n",
    "      return torch.cat(pred, dim=1).detach().cpu().numpy(), kl_sum\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nl081RMM42N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 126,
     "status": "ok",
     "timestamp": 1626217128372,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "-2DsuYRjGrvw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_variational(\n",
       "  (embedding): LinearReparameterization()\n",
       "  (lstm1): LSTMReparameterization(\n",
       "    (ih): LinearReparameterization()\n",
       "    (hh): LinearReparameterization()\n",
       "  )\n",
       "  (lstm2): LSTMReparameterization(\n",
       "    (ih): LinearReparameterization()\n",
       "    (hh): LinearReparameterization()\n",
       "  )\n",
       "  (decoder): LinearReparameterization()\n",
       "  (loss_fun): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTM_variational(2,128,256,2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903961,
     "status": "ok",
     "timestamp": 1626218033804,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "2g_bvInYjAJZ",
    "outputId": "d83ede94-42e2-4494-fd21-3f30485d61ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- \n",
      "epoch:  0\n",
      "Average training loss: 7.532e+03\n",
      "Average validation loss: 4.232e+00\n",
      "----- \n",
      "epoch:  1\n",
      "Average training loss: 1.041e+01\n",
      "Average validation loss: 4.416e+00\n",
      "----- \n",
      "epoch:  2\n",
      "Average training loss: 1.166e+01\n",
      "Average validation loss: 5.357e+00\n",
      "----- \n",
      "epoch:  3\n",
      "Average training loss: 1.170e+01\n",
      "Average validation loss: 4.954e+00\n",
      "----- \n",
      "epoch:  4\n",
      "Average training loss: 1.148e+01\n",
      "Average validation loss: 1.184e+01\n",
      "----- \n",
      "epoch:  5\n",
      "Average training loss: 1.132e+01\n",
      "Average validation loss: 9.148e+00\n",
      "----- \n",
      "epoch:  6\n",
      "Average training loss: 1.212e+01\n",
      "Average validation loss: 6.457e+00\n",
      "----- \n",
      "epoch:  7\n",
      "Average training loss: 1.075e+01\n",
      "Average validation loss: 4.434e+00\n",
      "----- \n",
      "epoch:  8\n",
      "Average training loss: 1.262e+01\n",
      "Average validation loss: 5.467e+00\n",
      "----- \n",
      "epoch:  9\n",
      "Average training loss: 1.040e+01\n",
      "Average validation loss: 3.909e+00\n",
      "----- \n",
      "epoch:  10\n",
      "Average training loss: 1.265e+01\n",
      "Average validation loss: 5.356e+00\n",
      "----- \n",
      "epoch:  11\n",
      "Average training loss: 1.203e+01\n",
      "Average validation loss: 8.531e+00\n",
      "----- \n",
      "epoch:  12\n",
      "Average training loss: 1.161e+01\n",
      "Average validation loss: 3.540e+00\n",
      "----- \n",
      "epoch:  13\n",
      "Average training loss: 1.148e+01\n",
      "Average validation loss: 4.136e+00\n",
      "----- \n",
      "epoch:  14\n",
      "Average training loss: 1.027e+01\n",
      "Average validation loss: 1.458e+01\n",
      "----- \n",
      "epoch:  15\n",
      "Average training loss: 1.373e+01\n",
      "Average validation loss: 3.661e+00\n",
      "----- \n",
      "epoch:  16\n",
      "Average training loss: 1.013e+01\n",
      "Average validation loss: 4.072e+00\n",
      "----- \n",
      "epoch:  17\n",
      "Average training loss: 1.064e+01\n",
      "Average validation loss: 3.270e+00\n",
      "----- \n",
      "epoch:  18\n",
      "Average training loss: 1.115e+01\n",
      "Average validation loss: 3.421e+00\n",
      "----- \n",
      "epoch:  19\n",
      "Average training loss: 1.100e+01\n",
      "Average validation loss: 5.295e+00\n",
      "----- \n",
      "epoch:  20\n",
      "Average training loss: 1.173e+01\n",
      "Average validation loss: 4.296e+00\n",
      "----- \n",
      "epoch:  21\n",
      "Average training loss: 1.212e+01\n",
      "Average validation loss: 5.339e+00\n",
      "----- \n",
      "epoch:  22\n",
      "Average training loss: 1.008e+01\n",
      "Average validation loss: 4.455e+00\n",
      "----- \n",
      "epoch:  23\n",
      "Average training loss: 9.839e+00\n",
      "Average validation loss: 5.314e+00\n",
      "----- \n",
      "epoch:  24\n",
      "Average training loss: 1.232e+01\n",
      "Average validation loss: 5.672e+00\n",
      "----- \n",
      "epoch:  25\n",
      "Average training loss: 1.077e+01\n",
      "Average validation loss: 9.821e+00\n",
      "----- \n",
      "epoch:  26\n",
      "Average training loss: 1.118e+01\n",
      "Average validation loss: 4.639e+00\n",
      "----- \n",
      "epoch:  27\n",
      "Average training loss: 1.039e+01\n",
      "Average validation loss: 6.644e+00\n",
      "----- \n",
      "epoch:  28\n",
      "Average training loss: 1.269e+01\n",
      "Average validation loss: 5.004e+00\n",
      "----- \n",
      "epoch:  29\n",
      "Average training loss: 1.113e+01\n",
      "Average validation loss: 1.014e+01\n",
      "----- \n",
      "epoch:  30\n",
      "Average training loss: 1.200e+01\n",
      "Average validation loss: 4.319e+00\n",
      "----- \n",
      "epoch:  31\n",
      "Average training loss: 1.275e+01\n",
      "Average validation loss: 5.585e+00\n",
      "----- \n",
      "epoch:  32\n",
      "Average training loss: 1.080e+01\n",
      "Average validation loss: 1.099e+01\n",
      "----- \n",
      "epoch:  33\n",
      "Average training loss: 1.277e+01\n",
      "Average validation loss: 1.159e+01\n",
      "----- \n",
      "epoch:  34\n",
      "Average training loss: 1.122e+01\n",
      "Average validation loss: 9.079e+00\n",
      "----- \n",
      "epoch:  35\n",
      "Average training loss: 1.125e+01\n",
      "Average validation loss: 4.497e+00\n",
      "----- \n",
      "epoch:  36\n",
      "Average training loss: 1.155e+01\n",
      "Average validation loss: 7.686e+00\n",
      "----- \n",
      "epoch:  37\n",
      "Average training loss: 1.140e+01\n",
      "Average validation loss: 5.063e+00\n",
      "----- \n",
      "epoch:  38\n",
      "Average training loss: 1.163e+01\n",
      "Average validation loss: 5.006e+00\n",
      "----- \n",
      "epoch:  39\n",
      "Average training loss: 1.024e+01\n",
      "Average validation loss: 7.520e+00\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Training the Model\n",
    "optimizer = optim.SGD(model.parameters(), lr=model_parameters.initial_lr)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.015)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.03)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.08) #nan\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.07) #nan \n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.06) #nan \n",
    "\n",
    "epochs = model_parameters.num_epochs\n",
    "num_mc = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    print(\"----- \")\n",
    "    print(\"epoch: \", epoch)\n",
    "    error = 0\n",
    "    total = 0\n",
    "    M     = len(batched_train_data)\n",
    "    for batch_idx, (data, target, _a , _b) in enumerate(batched_train_data):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data  = data.to(device)\n",
    "            target=target.to(device)\n",
    "\n",
    "        # Step 2. Run our forward pass and compute the losses\n",
    "        pred, nl_loss, kl_loss = model(data, target, training=True, num_mc=num_mc)\n",
    "        # TODO: Divide by the batch size\n",
    "        #pi     = (2.0**(M-batch_idx))/(2.0**M-1) #  Blundell?\n",
    "        loss   = nl_loss+ kl_loss\n",
    "        error += loss.detach().item()\n",
    "        total += len(target)\n",
    "\n",
    "        # Step 3. Compute the gradients, and update the parameters by\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Average training loss: {:.3e}\".format(error/total))\n",
    "\n",
    "    # Validation\n",
    "    error = 0\n",
    "    total = 0\n",
    "    M     = len(batched_val_data)\n",
    "    for batch_idx, (data_val, target_val, _ , _) in enumerate(batched_val_data):\n",
    "        if torch.cuda.is_available():\n",
    "            data_val  = data_val.to(device)\n",
    "            target_val=target_val.to(device)\n",
    "        pred_val, nl_loss, kl_loss = model(data_val, target_val)\n",
    "        pi     = (2.0**(M-batch_idx))/(2.0**M-1) # From Blundell\n",
    "        loss   = nl_loss+ pi*kl_loss\n",
    "        error += loss.detach().item()\n",
    "        total += len(target_val)\n",
    "\n",
    "    print(\"Average validation loss: {:.3e}\".format(error/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99A6ayLglGmV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1626218044464,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "LtBmwWGBHV4b"
   },
   "outputs": [],
   "source": [
    "def plot_traj(pred_traj, obs_traj_gt, pred_traj_gt, test_homography, background):\n",
    "    print(\"-----\")\n",
    "    homography = np.linalg.inv(test_homography)\n",
    "\n",
    "    # Convert it to absolute (starting from the last observed position)\n",
    "    displacement = np.cumsum(pred_traj, axis=0)\n",
    "    this_pred_out_abs = displacement + np.array([obs_traj_gt[-1].numpy()])\n",
    "\n",
    "    obs   = image_to_world_xy(obs_traj_gt, homography, flip=False)\n",
    "    gt    = image_to_world_xy(pred_traj_gt, homography, flip=False)\n",
    "    gt = np.concatenate([obs[-1,:].reshape((1,2)), gt],axis=0)\n",
    "    tpred   = image_to_world_xy(this_pred_out_abs, homography, flip=False)\n",
    "    tpred = np.concatenate([obs[-1,:].reshape((1,2)), tpred],axis=0)\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(background)\n",
    "    plt.plot(obs[:,0],obs[:,1],\"-b\", linewidth=2, label=\"Observations\")\n",
    "    plt.plot(gt[:,0], gt[:,1],\"-r\", linewidth=2, label=\"Ground truth\")\n",
    "    plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2, label=\"Prediction\")\n",
    "    plt.legend()\n",
    "    plt.title('Trajectory samples')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1HCeVlXQLYZVwBDinWWjWtxv6QEqFgd2u"
    },
    "executionInfo": {
     "elapsed": 61967,
     "status": "ok",
     "timestamp": 1626218110872,
     "user": {
      "displayName": "Mario Xavier Canche Uc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiOcz_C04Q59vq9Nh21kQKQXSGnCbhsfXYEXe1R4w=s64",
      "userId": "15987765480396593536"
     },
     "user_tz": 300
    },
    "id": "30joaw2kMWDY",
    "outputId": "4c9ae6b1-9a48-4b16-a59b-612ab8fd3024"
   },
   "outputs": [],
   "source": [
    "from obstacles import image_to_world_xy\n",
    "\n",
    "num_samples = 30\n",
    "num_monte_carlo = 20\n",
    "i = 1 # sample of batch\n",
    "bck = np.load('background.npy')\n",
    "\n",
    "# Testing\n",
    "cont = 0\n",
    "for batch_idx, (datarel_test, targetrel_test, data_test, target_test) in enumerate(batched_test_data):\n",
    "    print(\"-----\")\n",
    "    print(cont)\n",
    "    if torch.cuda.is_available():\n",
    "        datarel_test  = datarel_test.to(device)\n",
    "        targetrel_test= targetrel_test.to(device)\n",
    "        data_test     = data_test.to(device)\n",
    "        target_test   = target_test.to(device)        \n",
    "    homography = np.linalg.inv(test_homography)\n",
    "    \n",
    "    obs_traj_gt  = data_test[i,:,:]\n",
    "    pred_traj_gt = target_test[i,:,:]\n",
    "    obs   = image_to_world_xy(obs_traj_gt.cpu(), homography, flip=False)\n",
    "    gt    = image_to_world_xy(pred_traj_gt.cpu(), homography, flip=False)\n",
    "    gt = np.concatenate([obs[-1,:].reshape((1,2)), gt], axis=0)\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(bck)\n",
    "    plt.plot(obs[:,0],obs[:,1],\"-b\", linewidth=2, label=\"Observations\")\n",
    "    plt.plot(gt[:,0], gt[:,1],\"-r\", linewidth=2, label=\"Ground truth\")\n",
    "\n",
    "    # prediction\n",
    "    for mc_run in range(num_monte_carlo):\n",
    "        pred, kl = model.predict(datarel_test, dim_pred=12)\n",
    "        # ploting \n",
    "        #plot_traj(pred[i,:,:], data_test[i,:,:], target_test[i,:,:], test_homography, bck)\n",
    "\n",
    "        pred_traj = pred[i,:,:]\n",
    "\n",
    "        # Convert it to absolute (starting from the last observed position)\n",
    "        displacement      = np.cumsum(pred_traj, axis=0)\n",
    "        this_pred_out_abs = displacement + np.array([obs_traj_gt[-1].cpu().numpy()])\n",
    "\n",
    "        tpred = image_to_world_xy(this_pred_out_abs, homography, flip=False)\n",
    "        tpred = np.concatenate([obs[-1,:].reshape((1,2)), tpred], axis=0)\n",
    "\n",
    "        if mc_run == 0:\n",
    "            plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2, label=\"Prediction\")\n",
    "        else:\n",
    "            plt.plot(tpred[:,0],tpred[:,1],\"-g\", linewidth=2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('Trajectory samples')\n",
    "    plt.savefig(\"traj_variational_1_4\"+str(cont)+\".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    cont += 1\n",
    "        \n",
    "    if cont == num_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpU2HvaQKObj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRpI157sKOeG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n38rE4UKKOhC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Prueba_con_torch_variacional.ipynb",
   "provenance": [
    {
     "file_id": "19NEdCOFkz192E98RYrt3dC_jtWhqp8BR",
     "timestamp": 1612389852697
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
